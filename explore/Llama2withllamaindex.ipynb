{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG system using Llama2 with Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\genai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pypdf \n",
    "import transformers\n",
    "import accelerate\n",
    "import langchain\n",
    "import torch\n",
    "import bitsandbytes\n",
    "import einops\n",
    "import llama_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for Embedding \n",
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all the pdf's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\genai\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\genai\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\genai\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\genai\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\genai\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "# SErvice context combines llama2 model with the prompt \n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.prompts.prompts import SimpleInputPrompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='d76cf665-6a4e-45fd-97d7-b76a9d054f06', embedding=None, metadata={'page_label': '1', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Convolutional Neural Networks (CNN)  \\nA Convolutional Neural Network (CNN)  is a type of neural network that is specifically designed  to work \\nwell with images and spatial data . It makes certain assumptions about the structure of the input (like an \\nimage being made up of pixels in a grid) and uses specialized layers to process this kind of data more \\nefficiently.  \\n \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='93c4f7a4-854d-4005-9a6b-9c9eb7ceb1c0', embedding=None, metadata={'page_label': '2', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Recurrent Neural Networks (RNN)  \\nA Recurrent Neural Network (RNN)  is a type of neural network that remembers past information  and \\nuses it to inform the current output . This makes RNNs great for sequential data , where the order of \\ninputs matters, like time series, speech, or text data.  \\nIn a standard neural network , we treat each input independently. For example, if you’re processing a \\nsentence, the network would treat each word as an individual input with no memory of the previous word.  \\nIn contrast, an RNN processes a sequence of inputs  (e.g., a sentence word by word) and remembers  \\nthe previous words to help understand the next one. This is crucial when the context or history matters, \\nlike predicting the next word in a sentence.  \\nIn an RNN, each neuron  (or \"cell\") has a loop, which allows it to pass information from one step to the \\nnext. Here’s how it works step -by-step:  \\n \\n  \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b974fb2a-142e-44ea-a369-de7bd9360e43', embedding=None, metadata={'page_label': '3', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Generative Adversarial Networks (GAN)  \\nA Generative Adversarial Network (GAN)  is a type of neural network architecture used to generate new \\ndata that is similar to the data it has been trained on. It’s made up of two networks that compete against \\neach other : a generator  and a discriminator . \\nThe goal of a GAN is to generate realistic -looking data  (like images) that are indistinguishable from real \\ndata.  \\n \\n  \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d35d4489-9676-4c76-aace-ca104fab95b9', embedding=None, metadata={'page_label': '4', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' \\n \\n  \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8af90cb6-4379-4a2e-af33-9db7b83064f2', embedding=None, metadata={'page_label': '5', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Large Language Models (LLM)  \\nA Large Language Model (LLM)  is a type of neural network designed to understand and generate human \\nlanguage. These models are trained on massive amounts of text data and can perform tasks like \\nanswering questions, generating text, summarizing content, translating languages, and much more.  \\nLLMs are based on the Transformer architecture , which allows them to process and generate text \\nefficiently, even with long sequences of words or sentences.  \\nIn traditional neural networks, each input is processed in a fixed, independent manner, without much \\nconsideration of the relationships between inputs. In contrast, LLMs are built to understand language , \\nmeaning they consider the relationships between words in a sequence and the broader context.  \\nAt the core of an LLM is a Transformer model . The key innovation that makes Transformers powerful is \\ntheir use of attention mechanisms  that allow the model to focus on important parts of the input when \\nmaking predictions. Here’s how it works:  ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c86f0c30-d739-4aab-b276-1fba24583ac0', embedding=None, metadata={'page_label': '6', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' \\n  \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='778ff196-4a55-4406-89cc-473b0ce8aedc', embedding=None, metadata={'page_label': '7', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Generative AI (GenAI)  \\nGenerative AI  refers to a class of artificial intelligence models that are capable of generating new \\ncontent—such as text, images, music, code, or even videos. Instead of just recognizing patterns or \\nmaking predictions like traditional AI, generative AI can create entirely new data that resembles the data \\nit was trained on.  \\nGenerative AI models work by learning the patterns  and structures  in the training data and using that \\nunderstanding to create new examples. The key behind generative AI is that it tries to mimic the data \\ndistribution  of the real -world data it has seen.  \\nGenerative AI models come in different forms, with the most common types being GANs, VAEs \\n(Variational Autoencoders) , and Transformers  (used in LLMs like GPT for text generation).  \\n \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='58c5dd52-ca1b-4a96-91ca-0aab873750d6', embedding=None, metadata={'page_label': '8', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' \\n \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fd9f666a-733d-4db4-88dc-ace149900efb', embedding=None, metadata={'page_label': '9', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' \\n  \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7851a681-7d63-4628-a8f5-e23434209e5c', embedding=None, metadata={'page_label': '10', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Transformer Models  \\nTransformer models  are a type of neural network architecture designed to handle sequential data , like \\nlanguage, efficiently. They are widely used for tasks like text generation , translation , summarization , \\nand more. The key feature of Transformer models is their use of self-attention mechanisms , which allow \\nthe model to focus on important parts of the input sequence when processing data.  \\nTransformers are the foundation of many state -of-the-art models, including GPT, BERT, and T5. \\n \\n \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f54e150b-bf95-4533-97da-1f7fb4e1ec91', embedding=None, metadata={'page_label': '11', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' \\n \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b11fd204-efd6-45d2-9eea-7b7a9c319069', embedding=None, metadata={'page_label': '12', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Diffusion Models  \\nDiffusion models  are a type of generative model designed to create new data, such as images, by \\ngradually denoising  a random input. They work by learning how to reverse the process of adding noise to \\ndata, such as images, and can generate highly detailed and realistic outputs. Diffusion models have \\nbecome popular in tasks like image generation  and are seen as a powerful alternative to GANs for \\ncertain types of data generation.  \\n \\n \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cdc5f724-3b48-42bd-acc0-1a1ecd357660', embedding=None, metadata={'page_label': '13', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' \\n \\n  \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7b732ce9-b978-4c8b-b18c-64680951fd2e', embedding=None, metadata={'page_label': '14', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Multimodal Modals  \\nMultimodal models  are AI models designed to handle and integrate multiple types of data —such as text, \\nimages, audio, or video —at the same time. Unlike traditional models that work with just one type of data \\n(like text in language models or images in CNNs), multimodal models  combine different data modalities \\nto generate more context-aware and comprehensive outputs . \\nFor example, a multimodal model might be able to generate text descriptions of an image , answer \\nquestions based on an image , or even produce captions for videos  by understanding both visual and \\ntextual information.  \\nMultimodal models learn how to combine information from different data types  (modalities) by using \\nspecialized architectures, such as Transformers , to understand relationships between different kinds of \\ninputs. This allows them to generate outputs that reflect the combined meaning or insights from multiple \\ntypes of data.  \\nFor instance, a multimodal model might use text and image inputs together to generate a rich description \\nof the image that captures both visual and linguistic context.  \\n \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d2256a47-3ce3-4074-af47-6361b7c1a221', embedding=None, metadata={'page_label': '15', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' \\n \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='17e3c41a-b9b7-40e1-bedc-216b888a47dc', embedding=None, metadata={'page_label': '16', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Transfer Learning and Pre -trained Models  \\nTransfer learning  is a technique in machine learning where a model trained on one task is reused or \\nfine-tuned for another related task. Instead of starting from scratch, the model builds on knowledge it \\nhas already learned  from a previous task, making the process faster and more efficient, especially when \\nthere’s limited data for the new task.  \\nThis approach is widely used in modern AI, particularly in large neural networks and pre-trained models , \\nwhere a model is pre -trained on a large dataset (like ImageNet or a large text corpus) and then fine -tuned \\non a smaller, task -specific dataset.  \\nTransfer learning works by transferring knowledge  from a model that has already been trained on one \\ntask to a new, but related, task. This allows the model to leverage pre-learned features  (such as patterns \\nin images or language) for the new task.  \\nFor example, a model trained on millions of images can learn general features like edges, shapes, and \\ntextures. When fine -tuned for a new task (like classifying medical images), these pre -learned features \\nhelp the model quickly adapt without needing as muc h data.  \\n \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9afa1542-49da-4de6-a358-ddb0053da788', embedding=None, metadata={'page_label': '17', 'file_name': 'Neural Networks and AI Advances.pdf', 'file_path': 'd:\\\\pythonProjects\\\\RAG_finetuning\\\\data\\\\Neural Networks and AI Advances.pdf', 'file_type': 'application/pdf', 'file_size': 773786, 'creation_date': '2024-11-06', 'last_modified_date': '2024-10-29'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' \\n \\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=SimpleDirectoryReader('data').load_data()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\" \n",
    "You are a Q&A assistant. Your goal is to answer questions as accurately \n",
    "as possible based on the instructions and context provided.\n",
    "\"\"\"\n",
    "## Default format supportable by Llama2 \n",
    "query_wrapper_prompt=SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved in your configured git credential helpers (manager).\n",
      "Your token has been saved to C:\\Users\\26amr\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "#login for llama 2 models \n",
    "import os\n",
    "import dotenv\n",
    "from huggingface_hub import login\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "login(token=os.getenv('HUGGINGFACEHUB_API_TOKEN'),add_to_git_credential=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.51s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "# call llama2 model from HuggingFace\n",
    "import torch\n",
    "llm=HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={'temperature':0.0,'do_sample':False},\n",
    "    system_prompt=system_prompt,\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    device_map='auto',\n",
    "    model_kwargs={'torch_dtype':torch.float16,'load_in_8bit':True, 'llm_int8_enable_fp32_cpu_offload': True }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\26amr\\AppData\\Local\\Temp\\ipykernel_26500\\3889585389.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model=LangchainEmbedding(HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n",
      "d:\\anaconda\\envs\\genai\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\26amr\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "embed_model=LangchainEmbedding(HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# service context\n",
    "- combine all the techniques and bundle them together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.chunk_size=1024\n",
    "Settings.embed_model=embed_model\n",
    "Settings.llm=llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use vector store index and conver this entire data into indexes\n",
    "index=VectorStoreIndex.from_documents(documents=documents, embed_model=Settings.embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x18419f69b40>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine=index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\genai\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\genai\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "response=query_engine.query('how do we utilize neural network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utilizing neural networks can be done by first inputting data into layers of neurons hooked together forming layers stacked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked together layers hooked'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
